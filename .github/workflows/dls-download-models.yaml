name: "[DLS] Models update on self-hosted runners"
run-name: "[DLS] Models update on self-hosted runners (by @${{ github.actor }} via ${{ github.event_name }})"
on:
  schedule:
    - cron: '0 5 * * MON' # 5:00 UTC each Monday
  workflow_dispatch:
    inputs:
      models_to_download:
        description: 'Which models to download?'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - public
          - omz
          - specified_model
      model_name:
        description: 'What model do you want to download?'
        required: false
        type: string
      model_path:
        description: 'Where do you want to download your specific model? (pulic/omz)'
        required: false
        type: string

permissions: {}
env:
  MODELS_PATH: "$HOME/models"

jobs:
  update_linux_hosts:
    name: Update on Linux runners
    runs-on: ${{ matrix.host_labels }}
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        include:
          - host_labels: [self-hosted, DLS-ARL-01]
          - host_labels: [self-hosted, DLS-ARL-02]
          - host_labels: [self-hosted, DLS-TGL-01]
          - host_labels: [self-hosted, DLS-TGL-02]
          - host_labels: [self-hosted, DLS-TGL-03]
          - host_labels: [self-hosted, DLS-TGL-04]
          - host_labels: [self-hosted, DLS-TGL-05]
    steps:
    - name: Get script
      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 #4.2.2
      with:
        persist-credentials: false
        path: edge-ai-libraries-repo
        sparse-checkout: |
          libraries/dl-streamer/samples/download_public_models.sh
          libraries/dl-streamer/samples/download_omz_models.sh
          libraries/dl-streamer/samples/models_omz_samples.lst
        sparse-checkout-cone-mode: false

    - name: Download only specific model
      if: ${{ inputs.models_to_download == 'specified_model' }} 
      run: |
        MODEL_PATH=${{ inputs.model_path }}
        MODEL_NAME=${{ inputs.model_name }}
        export MODELS_PATH=${{ env.MODELS_PATH }}
        echo "MODEL_PATH=[$MODEL_PATH]"
        echo "MODEL_PATH bytes:"
        echo -n "$MODEL_PATH" | od -c
        if [[ "$MODEL_PATH" == "public" ]]; then
          ./edge-ai-libraries-repo/libraries/dl-streamer/samples/download_public_models.sh "$MODEL_NAME" coco128
          if [ -z "$( ls -A ${{ env.MODELS_PATH }}/public/$MODEL_NAME )" ]; then
            echo "$MODEL_NAME model not downloaded correctly ❌"
            echo "$MODEL_NAME model not downloaded correctly ❌"❌" >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "$MODEL_NAME model downloaded correctly ✅"
            echo "$MODEL_NAME model downloaded correctly ✅" >> $GITHUB_STEP_SUMMARY
          fi
        elif [[ "$MODEL_PATH" == "omz" ]]; then
          mkdir -p .virtualenvs/dlstreamer
          python3 -m venv .virtualenvs/dlstreamer
          source .virtualenvs/dlstreamer/bin/activate
          pip3 install --no-cache-dir --upgrade tensorflow openvino-dev[onnx] torch
          export MODELS_PATH=${{ env.MODELS_PATH }}
          ./edge-ai-libraries-repo/libraries/dl-streamer/samples/download_omz_models.sh $MODEL_NAME
          deactivate
          if [ -z "$( ls -A ${{ env.MODELS_PATH }}/intel/$MODEL_NAME )" ]; then
            echo "$MODEL_NAME model not downloaded correctly ❌"
            echo "$MODEL_NAME model not downloaded correctly ❌"❌" >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "$MODEL_NAME model downloaded correctly ✅"
            echo "$MODEL_NAME model downloaded correctly ✅" >> $GITHUB_STEP_SUMMARY
          fi
        fi

    - name: Prepare directory for public models
      if: ${{ inputs.models_to_download == 'public' || inputs.models_to_download == 'all' || github.event_name == 'schedule' }}
      run: |
        if [ -d "${{ env.MODELS_PATH }}/public" ]; then
          echo "Removing public models directory"
          rm -rf "${{ env.MODELS_PATH }}/public"
        fi

    - name: Prepare directory for OMZ models
      if: ${{ inputs.models_to_download == 'omz' || inputs.models_to_download == 'all' || github.event_name == 'schedule'  }}
      run: |
        if [ -d "${{ env.MODELS_PATH }}/intel" ]; then
          echo "Removing OMZ models directory"
          rm -rf "${{ env.MODELS_PATH }}/intel"
        fi

    - name: Download public models
      if: ${{ inputs.models_to_download == 'public' || inputs.models_to_download == 'all' || github.event_name == 'schedule'  }}
      run: |
        export MODELS_PATH=${{ env.MODELS_PATH }}
        echo "Downloading public models"
        ./edge-ai-libraries-repo/libraries/dl-streamer/samples/download_public_models.sh all coco128

    - name: Download OMZ models (setup venv, dependencies and download)
      if: ${{ inputs.models_to_download == 'omz' || inputs.models_to_download == 'all' || github.event_name == 'schedule'  }}
      run: |
        mkdir -p .virtualenvs/dlstreamer
        python3 -m venv .virtualenvs/dlstreamer
        source .virtualenvs/dlstreamer/bin/activate
        pip3 install --no-cache-dir --upgrade tensorflow openvino-dev[onnx] torch
        export MODELS_PATH=${{ env.MODELS_PATH }}
        ./edge-ai-libraries-repo/libraries/dl-streamer/samples/download_omz_models.sh
        deactivate

    - name: Verify public models downloading
      if: ${{ inputs.models_to_download == 'public' || inputs.models_to_download == 'all' || github.event_name == 'schedule'  }}
      run: |
        if [ -z "$( ls -A ${{ env.MODELS_PATH }}/public )" ]; then
          echo "Public models not downloaded correctly ❌"
          echo "Public models not downloaded ❌" >> $GITHUB_STEP_SUMMARY
          exit 1
        else
          echo "Public models downloaded ✅"
          echo "Public models downloaded ✅" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Verify OMZ models downloading
      if: ${{ inputs.models_to_download == 'omz' || inputs.models_to_download == 'all' || github.event_name == 'schedule'  }}
      run: |
        if [ -z "$( ls -A ${{ env.MODELS_PATH }}/intel )" ]; then
          echo "Open Model Zoo models not downloaded correctly ❌"
          echo "Open Model Zoo models not downloaded ❌" >> $GITHUB_STEP_SUMMARY
          exit 1
        else
          echo "Open Model Zoo models downloaded ✅"
          echo "Open Model Zoo models downloaded ✅" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Clean up
      if: always()
      run: |
        rm -rf edge-ai-libraries-repo .virtualenvs
        rm -rf $HOME/.virtualenvs
