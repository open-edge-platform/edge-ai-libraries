global:
  huggingface:
    apiToken: <huggingface-api-token> # Set this during installation
  proxy:
    no_proxy: <no-proxy>
    http_proxy: <http-proxy>
    https_proxy: <http-proxy>
  UI_NODEPORT: <ui-nodeport>
  POSTGRES_USER: <postgres-user>
  POSTGRES_PASSWORD: <postgres-password>
  MINIO_ROOT_USER: <minio-root-user>
  MINIO_ROOT_PASSWORD: <minio-root-password>
  LLM_MODEL: <llm-model>
  EMBEDDING_MODEL_NAME: <embedding-model-name>
  RERANKER_MODEL: <reranker-model>
  OTLP_ENDPOINT: <otlp-endpoint>
  OTLP_ENDPOINT_TRACE: <otlp-endpoint-trace>
  teiEmbeddingService:
    enabled: false
  ovmsEmbeddingService:
    enabled: false
  egai_minio_pvc:
    size: 20Gi
  egai_reranker_pvc:
    size: 20Gi
  egai_ovms_pvc:
    size: 20Gi
  egai_ovms_embed_pvc:
    size: 20Gi

Chatqna:
  name: chatqna-backend
  image:
    repository: intel/chatqna
    tag: "1.1.2"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8100
    targetPort: 8080
  env:
    ENDPOINT_URL: http://ovms
    INDEX_NAME: intel-rag
    FETCH_K: 10
    PORT_DB: 5432/langchain
    SERVICE_NAME: chatqna
    SERVICE_ENV: chatqna
    OTEL_METRICS_EXPORTER: otlp
    OTEL_TRACES_EXPORTER: otlp
    REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
    PG_CONNECTION_STRING: postgresql+psycopg://

dataprepPgvector:
  name: document-ingestion
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000

tgiService:
  name: text-generation-service
  enabled: false
  service:
    port: 8080
vllmService:
  name: vllm-service
  enabled: false
  service:
    port: 8080
ovmsService:
  name: ovmsService
  enabled: true
  service:
    port: 8300
reranker:
  service:
    port: 8090
chatqnaui:
  name: chatqna-ui
  nameOverride: "ui"
  service:
    port: 80
