---
openapi: 3.1.0
info:
  title: Audio Analyzer Service API
  description: API for intelligent audio processing including speech transcription
    and audio event detection
  version: 1.0.0
servers:
- url: "/audio"
paths:
  "/api/v1/health":
    get:
      tags:
      - Health API
      summary: Health status of API
      description: |-
        Health check endpoint.

        Returns:
            A response indicating the service status, version and a descriptive message.
      operationId: health_check_api_v1_health_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/HealthResponse"
  "/api/v1/transcriptions":
    post:
      tags:
      - Transcription API
      summary: Transcribe audio from uploaded video file or a video stored at Minio
      description: "Transcribe speech from a video file.\n\nUpload a video file directly
        or specify MinIO parameters to transcribe its audio content.\n\nTwo ways to
        provide the video:\n- Upload a video file using form-data\n- Specify MinIO
        parameters (minio_bucket, video_id, video_name) to retrieve from storage\n
        \nArgs:\n    request: Form data containing the file or MinIO parameters and
        transcription settings\n    language: Optional language code for transcription\n\nReturns:\n
        \   A response with the transcription status and details"
      operationId: transcribe_video_api_v1_transcriptions_post
      parameters:
      - name: language
        in: query
        required: false
        schema:
          type: string
          description: _(Optional)_ Language for transcription. If not provided, auto-detection
            will be used.
          title: Language
        description: _(Optional)_ Language for transcription. If not provided, auto-detection
          will be used.
      requestBody:
        content:
          multipart/form-data:
            schema:
              "$ref": "#/components/schemas/Body_transcribe_video_api_v1_transcriptions_post"
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/TranscriptionResponse"
        '400':
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/ErrorResponse"
          description: Bad Request
        '422':
          description: Invalid request body or parameter provided
        '500':
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/ErrorResponse"
          description: Internal Server Error
  "/api/v1/models":
    get:
      tags:
      - Models API
      summary: Get list of models available for use with detailed information
      description: "Get a list of available Whisper model variants that can be used
        for transcription.\n\nThis endpoint returns all the whisper models that are
        configured in the service\nand available for transcription requests, along
        with detailed information including\ndisplay names, descriptions, and the
        default model that is used when no specific \nmodel is requested.\n\nReturns:\n
        \   A response with the list of available models with their details and the
        default model"
      operationId: get_available_models_api_v1_models_get
      responses:
        '200':
          description: Successful Response
          content:
            application/json:
              schema:
                "$ref": "#/components/schemas/AvailableModelsResponse"
components:
  schemas:
    AvailableModelsResponse:
      properties:
        models:
          items:
            "$ref": "#/components/schemas/WhisperModelInfo"
          type: array
          title: Models
          description: List of available whisper model variants with detailed information
        default_model:
          type: string
          title: Default Model
          description: The default model used for transcription
      type: object
      required:
      - models
      - default_model
      title: AvailableModelsResponse
      description: Response schema for listing available models endpoint
      examples:
      - default_model: tiny.en
        models:
        - description: English only version of tiny whisper model. Significantly less
            accuracy, extremely fast inference.
          display_name: Tiny (English)
          model_id: tiny.en
        - description: English only version of base whisper model.
          display_name: Base Model (English)
          model_id: base.en
    Body_transcribe_video_api_v1_transcriptions_post:
      properties:
        minio_bucket:
          type: string
          title: Minio Bucket
          description: MinIO bucket containing the video file. Required if not using
            filsystem for video source.
          default: ''
        video_id:
          type: string
          title: Video Id
          description: ID/prefix of the video in the MinIO bucket. Required if not
            using filsystem for video source.
          default: ''
        video_name:
          type: string
          title: Video Name
          description: Name of the video file in the MinIO bucket. Required if not
            using filsystem for video source.
          default: ''
        device:
          "$ref": "#/components/schemas/DeviceType"
          title: Device
          description: '_(Optional)_ Device to use for transcription - ''cpu'' or
            ''auto''. **Default value : cpu**'
          default: cpu
        model_name:
          "$ref": "#/components/schemas/EnabledWhisperModels"
          title: Model Name
          description: '_(Optional)_ Variant of the whisper model to use. **Default
            value : ''small.en'' or first available model**'
          default: ''
        include_timestamps:
          type: boolean
          title: Include Timestamps
          description: '_(Optional)_ A flag to include timestamps in the transcription
            output. **Default value : True**'
          default: true
        file:
          type: string
          format: binary
          title: File
          description: Select video file to be transcribed. Optional if using MinIO
            source.
      type: object
      title: Body_transcribe_video_api_v1_transcriptions_post
    DeviceType:
      type: string
      enum:
      - cpu
      - gpu
      - auto
      title: DeviceType
      description: Enum for the device types available for transcription
    EnabledWhisperModels:
      type: string
      enum:
      - tiny.en
      - small.en
      - medium.en
      title: EnabledWhisperModels
    ErrorResponse:
      properties:
        error_message:
          type: string
          title: Error Message
          description: Human-readable error message
        details:
          anyOf:
          - type: string
          - type: 'null'
          title: Details
          description: Additional error details
      type: object
      required:
      - error_message
      title: ErrorResponse
      description: Response schema for errors
      examples:
      - details: Invalid file format
        error_message: Failed to process video file
    HealthResponse:
      properties:
        status:
          type: string
          title: Status
          description: Current health status of the API
          default: healthy
        version:
          type: string
          title: Version
          description: API version
          default: 1.0.0
        message:
          type: string
          title: Message
          description: Detailed status message
          default: Service is running smoothly.
      type: object
      title: HealthResponse
      description: Response schema for the health check endpoint
      examples:
      - message: Service is running smoothly.
        status: healthy
        version: 1.0.0
    TranscriptionResponse:
      properties:
        status:
          "$ref": "#/components/schemas/TranscriptionStatus"
          description: Current status of the transcription job
        message:
          type: string
          title: Message
          description: Human-readable status message
        job_id:
          anyOf:
          - type: string
          - type: 'null'
          title: Job Id
          description: Unique identifier for the transcription job
        transcript_path:
          anyOf:
          - type: string
          - type: 'null'
          title: Transcript Path
          description: Path to the transcript file
        video_name:
          anyOf:
          - type: string
          - type: 'null'
          title: Video Name
          description: Name of the processed video file
        video_duration:
          anyOf:
          - type: number
          - type: 'null'
          title: Video Duration
          description: Duration of the video in seconds
      type: object
      required:
      - status
      - message
      title: TranscriptionResponse
      description: Response schema for the transcription endpoint
      examples:
      - job_id: 1234-5678-90ab-cdef
        message: Transcription completed successfully
        status: completed
        transcript_path: "/transcripts/meeting_recording.txt"
        video_duration: 120.5
        video_name: meeting_recording.mp4
    TranscriptionStatus:
      type: string
      enum:
      - pending
      - processing
      - completed
      - failed
      title: TranscriptionStatus
      description: Enum for the status of a transcription job
    WhisperModelInfo:
      properties:
        model_id:
          type: string
          title: Model Id
        display_name:
          type: string
          title: Display Name
        description:
          type: string
          title: Description
      type: object
      required:
      - model_id
      - display_name
      - description
      title: WhisperModelInfo
      description: Schema for an individual whisper model's detailed information
