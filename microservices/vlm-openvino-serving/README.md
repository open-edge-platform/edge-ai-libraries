# VLM OpenVINO Serving Microservice

This repository provides a VLM microservice which is a FastAPI-based wrapping on top of OpenVINO. The microservice helps provide OpenAI API compliant microservice supporting VLMs which are not supported yet in OpenVINO model serving (OVMS).

Below, you'll find links to detailed documentation to help you get started, configure, and deploy the microservice.

## Documentation

- **Overview**
  - [Overview](docs/user-guide/Overview.md): A high-level introduction to the microservice.

- **Getting Started**
  - [Get Started](docs/user-guide/get-started.md): Step-by-step guide to getting started with the microservice.
  - [System Requirements](docs/user-guide/system-requirements.md): Hardware and software requirements for running the microservice.

- **Deployment**
  - [How to Build from Source](docs/user-guide/how-to-build-from-source.md): Instructions for building the microservice from source code.

- **API Reference**
  - [API Reference](docs/user-guide/api-reference.md): Comprehensive reference for the available REST API endpoints.

- **Release Notes**
  - [Release Notes](docs/user-guide/release-notes.md): Information on the latest updates, improvements, and bug fixes.


